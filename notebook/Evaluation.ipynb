{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce70eebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import albumentations\n",
    "import math\n",
    "from scipy.special import softmax\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from models.ResNext50 import Myresnext50\n",
    "from train.train_classification import trainer_classification\n",
    "from utils.utils import configure_optimizers\n",
    "from Datasets.DataLoader import ImageDataset\n",
    "\n",
    "### PyTorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "\n",
    "# Data paths\n",
    "train_data = glob.glob('data/train/*/*')\n",
    "val_data = glob.glob('data/val/*/*')\n",
    "\n",
    "labels = [x.split('/')[-2] for x in train_data]\n",
    "cell_types = set(labels)\n",
    "cell_types = list(cell_types)\n",
    "cell_types.sort()\n",
    "\n",
    "cell_types_df = pd.DataFrame(cell_types, columns=['Cell_Types'])\n",
    "cell_types_df['Cell_Types'] = cell_types_df['Cell_Types'].astype('category')\n",
    "cell_types_df['Cell_Types_Cat'] = cell_types_df['Cell_Types'].cat.codes\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc_df = pd.DataFrame(enc.fit_transform(cell_types_df[['Cell_Types_Cat']]).toarray())\n",
    "cell_types_df = cell_types_df.join(enc_df)\n",
    "\n",
    "# Normalization pipeline\n",
    "\n",
    "transform_pipeline = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Normalize(mean=(0.5642, 0.5026, 0.6960), std=(0.2724,\n",
    " 0.2838, 0.2167)),\n",
    "\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Model setup\n",
    "resnext50_pretrained = torch.hub.load('pytorch/vision:v0.10.0', 'resnext50_32x4d')\n",
    "My_model = Myresnext50(my_pretrained_model=resnext50_pretrained, num_classes=23)\n",
    "\n",
    "checkpoint_PATH = 'checkpoints/model_checkpoint.ckpt'\n",
    "checkpoint = torch.load(checkpoint_PATH)\n",
    "\n",
    "def remove_data_parallel(old_state_dict):\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in old_state_dict.items():\n",
    "        name = k[7:]  # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "    return new_state_dict\n",
    "\n",
    "checkpoint = remove_data_parallel(checkpoint['model_state_dict'])\n",
    "My_model.load_state_dict(checkpoint, strict=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7219444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "My_model = My_model.cuda().eval()\n",
    "dataset = ImageDataset(img_list=val_data, split='viz', df=cell_types_df, transform=transform_pipeline)\n",
    "dataloader = DataLoader(dataset, batch_size=32, num_workers=2, shuffle=False)\n",
    "\n",
    "# Initialize prediction storage\n",
    "predictions = []\n",
    "labels = []\n",
    "hidden_features = []\n",
    "sample_ids = []\n",
    "\n",
    "# Batch processing\n",
    "for i, batch in enumerate(dataloader):\n",
    "    # Process first batch\n",
    "    if i == 0:\n",
    "        images = batch[\"image\"].cuda()\n",
    "        batch_labels = batch[\"label\"]\n",
    "        # Generate anonymized sample IDs\n",
    "        sample_ids = [f\"sample_{idx}\" for idx in range(len(batch['ID']))]\n",
    "        \n",
    "        # Get model predictions\n",
    "        batch_pred_probs = My_model(images)\n",
    "        batch_hidden_features = My_model.pretrained(images)\n",
    "\n",
    "        # Convert to numpy arrays\n",
    "        predictions = torch.flatten(batch_pred_probs, start_dim=1).detach().cpu().numpy()\n",
    "        labels = torch.flatten(batch_labels, start_dim=1).cpu().numpy()\n",
    "        hidden_features = torch.flatten(batch_hidden_features, start_dim=1).detach().cpu().numpy()\n",
    "    \n",
    "    # Process subsequent batches\n",
    "    else:\n",
    "        images = batch[\"image\"].cuda()\n",
    "        batch_labels = batch[\"label\"]\n",
    "        batch_sample_ids = [f\"sample_{len(sample_ids) + idx}\" for idx in range(len(batch['ID']))]\n",
    "        \n",
    "        batch_pred_probs = My_model(images)\n",
    "        batch_hidden_features = My_model.pretrained(images)\n",
    "        \n",
    "        batch_pred_probs = torch.flatten(batch_pred_probs, start_dim=1).detach().cpu().numpy()\n",
    "        batch_labels = torch.flatten(batch_labels, start_dim=1).cpu().numpy()\n",
    "        batch_hidden_features = torch.flatten(batch_hidden_features, start_dim=1).detach().cpu().numpy()\n",
    "        \n",
    "        # Concatenate results\n",
    "        sample_ids.extend(batch_sample_ids)\n",
    "        predictions = np.concatenate((predictions, batch_pred_probs))\n",
    "        labels = np.concatenate((labels, batch_labels))\n",
    "        hidden_features = np.concatenate((hidden_features, batch_hidden_features))\n",
    "\n",
    "# Apply softmax to predictions\n",
    "predictions = softmax(predictions, axis=1)\n",
    "\n",
    "# Print shapes for verification\n",
    "print(f\"Predictions shape: {predictions.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n",
    "print(f\"Hidden features shape: {hidden_features.shape}\")\n",
    "print(f\"Number of samples: {len(sample_ids)}\")\n",
    "\n",
    "# Generate class predictions\n",
    "class_predictions = np.zeros_like(predictions)\n",
    "for i in range(predictions.shape[0]):\n",
    "    class_predictions[i] = (predictions[i] == np.max(predictions[i])).astype(int)\n",
    "\n",
    "print(f\"Class predictions shape: {class_predictions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b982858",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = pd.DataFrame(data=labels, index=sample_ids, columns=cell_types_df['Cell_Types'].tolist())\n",
    "pred_prob = pd.DataFrame(data=predictions, index=sample_ids, columns=cell_types_df['Cell_Types'].tolist())\n",
    "pred_class = pd.DataFrame(data=predictions, index=sample_ids, columns=cell_types_df['Cell_Types'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2d8d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (roc_auc_score, accuracy_score, recall_score, precision_score, f1_score)\n",
    "from scipy.special import softmax\n",
    "def evaluation_metrics_multiclass(label, pred_prob, pred_class):\n",
    "    #creating a set of all the unique classes using the actual class list\n",
    "    classes = label.columns\n",
    "    eval_dict = {}\n",
    "    \n",
    "    for per_class in classes:\n",
    "        #creating a list of all the classes except the current class \n",
    "        groundtruth_per_class  = label[per_class].tolist()\n",
    "        pred_prob_per_class    = pred_prob[per_class].tolist()\n",
    "        pred_class_per_class = pred_class[per_class].tolist()\n",
    "        #marking the current class as 1 and all other classes as 0\n",
    "\n",
    "        roc_auc = roc_auc_score(groundtruth_per_class, pred_prob_per_class)\n",
    "        f1 = f1_score(groundtruth_per_class, pred_class_per_class)\n",
    "        acc = accuracy_score(groundtruth_per_class, pred_class_per_class)\n",
    "        precision = precision_score(groundtruth_per_class, pred_class_per_class)\n",
    "        recall = recall_score(groundtruth_per_class, pred_class_per_class)\n",
    "        used_metrics = ['AUC','F1','Acc','Precision','Recall']\n",
    "        eval_dict[per_class] = [roc_auc, f1, acc, precision, recall]\n",
    "\n",
    "    return eval_dict\n",
    "\n",
    "\n",
    "# assuming your already have a list of actual_class and predicted_class from the logistic regression classifier\n",
    "multiclass = evaluation_metrics_multiclass(label, pred_prob, pred_class)\n",
    "print(multiclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f41ed0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(multiclass)\n",
    "df.index = ['AUC','F1','Acc','Precision','Recall']\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73a474aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import one_vs_rest_metrics, get_overall_multiclass_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032d6a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_one_vs_rest = one_vs_rest_metrics(np.argmax(label.to_numpy(), axis=1),\n",
    "                    np.argmax(pred_class.to_numpy(), axis=1), \n",
    "                    pred_prob.to_numpy())\n",
    "df_one_vs_rest.index = cell_types_df['Cell_Types'].tolist()\n",
    "df_one_vs_rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a951cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_overall_multiclass_metrics = get_overall_multiclass_metrics(np.argmax(label.to_numpy(), axis=1),\n",
    "                    np.argmax(pred_class.to_numpy(), axis=1), \n",
    "                    pred_prob.to_numpy())\n",
    "df_overall_multiclass_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
